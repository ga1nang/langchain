{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPEN_AI_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# langsmith tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000001F147A09490> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001F147A08C50> root_client=<openai.OpenAI object at 0x000001F147871AF0> root_async_client=<openai.AsyncOpenAI object at 0x000001F147870530> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence systems designed to create new content, such as text, images, audio, video, and even code. These systems leverage machine learning models, especially deep learning networks like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer models, to generate content that is often indistinguishable from content created by humans.\\n\\nSome key characteristics of generative AI include:\\n\\n1. **Content Creation**: Generative AI can produce various types of content, including natural language text, realistic images, music compositions, and more.\\n\\n2. **Learning from Data**: These systems are trained on large datasets and learn to understand patterns, structures, and features in the data to generate new instances that fit well within the learned model.\\n\\n3. **Applications**: Generative AI has a wide range of applications, such as in creative industries for art and music generation, in entertainment for video game design, in business for automated content creation, and in technology for software development.\\n\\n4. **Examples**: Popular examples include OpenAI's GPT (Generative Pre-trained Transformer) models for text generation, DALL-E for image creation, and DeepMind's WaveNet for audio synthesis.\\n\\nGenerative AI is a rapidly evolving field, pushing the boundaries of what machines can create and offering new tools and opportunities for innovation across various sectors.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 280, 'prompt_tokens': 13, 'total_tokens': 293, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e5e4913e83', 'finish_reason': 'stop', 'logprobs': None} id='run-83e5f79f-75d4-41b2-8db7-f614241104ec-0' usage_metadata={'input_tokens': 13, 'output_tokens': 280, 'total_tokens': 293, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a suite of tools developed by Langchain to facilitate the development, testing, and monitoring of applications that leverage large language models (LLMs). It is designed to help developers optimize and manage their LLM-based applications more effectively. Langsmith offers features such as debugging and testing capabilities to ensure that applications behave as expected, as well as monitoring tools to track performance and usage. These features are integrated to support developers in creating robust and reliable applications using language models.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 33, 'total_tokens': 127, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_2f406b9113', 'finish_reason': 'stop', 'logprobs': None} id='run-31e4786a-7ffd-4893-8923-d440fd255742-0' usage_metadata={'input_tokens': 33, 'output_tokens': 94, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke(input=\"Can you tell me about Langsmith?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain, designed to assist in the development and optimization of applications that utilize large language models (LLMs). It provides a suite of features to help developers build, monitor, and evaluate LLM-based applications more effectively. Key features include:\n",
      "\n",
      "1. **Tracing and Debugging**: Langsmith allows developers to trace and debug their LLM applications by tracking the flow of data and interactions within the application. This helps identify and resolve issues more efficiently.\n",
      "\n",
      "2. **Evaluation and Feedback**: It provides mechanisms to evaluate the performance of language models through metrics and user feedback, enabling developers to refine and improve their models continuously.\n",
      "\n",
      "3. **Experimentation**: Langsmith supports the experimentation with different models and configurations, allowing developers to test variations and determine the most effective approach for their application.\n",
      "\n",
      "4. **Monitoring**: The tool offers monitoring capabilities to keep track of the application's performance in real-time, ensuring that any anomalies or issues can be quickly addressed.\n",
      "\n",
      "Overall, Langsmith is aimed at simplifying the process of working with large language models, making it easier for developers to create robust and reliable applications.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
